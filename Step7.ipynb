{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from sklearn.manifold import MDS\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run 'Step1.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run 'Step4.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run 'Step6.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 1 parents []\n",
      "node 2 parents ['1']\n",
      "node 3 parents ['2']\n",
      "node 4 parents ['2', '3']\n",
      "node 5 parents ['2']\n",
      "node 6 parents ['2']\n",
      "node 7 parents ['2']\n",
      "node 8 parents ['2']\n",
      "node 9 parents ['2']\n",
      "node 10 parents ['2']\n",
      "node 11 parents ['2', '3', '4']\n",
      "node 12 parents ['11']\n",
      "node 13 parents ['11']\n",
      "node 14 parents ['11']\n",
      "node 15 parents ['11']\n",
      "node 16 parents ['11']\n",
      "node 24 parents ['11', '13']\n",
      "node 25 parents ['11', '24']\n",
      "node 26 parents ['11', '24', '25']\n",
      "node 27 parents ['11', '25', '26']\n",
      "node 28 parents ['11', '24', '25', '26', '27']\n",
      "node 29 parents ['11', '28']\n",
      "node 30 parents ['11', '24', '28']\n",
      "node 32 parents ['11', '24', '28']\n",
      "node 33 parents ['11']\n",
      "node 34 parents ['11', '28']\n",
      "node 35 parents ['11', '30']\n",
      "node 36 parents ['11', '30', '35']\n",
      "node 37 parents ['11', '30', '35', '36']\n",
      "node 38 parents ['11', '30', '35', '36', '37']\n",
      "node 39 parents ['11', '30', '35', '36', '37', '38']\n",
      "node 44 parents ['11', '27', '28']\n",
      "node 45 parents ['11', '29']\n",
      "node 49 parents ['11', '26', '28']\n",
      "node 50 parents ['11', '27']\n",
      "node 52 parents ['11', '27', '50']\n",
      "node 56 parents ['11', '26', '27', '49', '50', '52']\n",
      "node 59 parents ['11', '28', '49', '56']\n",
      "node 65 parents ['11', '49', '56', '59']\n",
      "node 69 parents ['11', '25', '26', '28', '49']\n",
      "node 70 parents ['11', '25', '26', '28', '49', '69']\n",
      "node 71 parents ['11', '25', '26', '28', '59', '69', '70']\n",
      "node 72 parents ['11', '26', '28', '49', '69', '70', '71']\n",
      "node 73 parents ['11', '27', '28']\n",
      "node 17 parents ['24']\n",
      "node 18 parents ['24', '27', '56', '17']\n",
      "node 19 parents ['24', '17', '18']\n",
      "node 20 parents ['24', '17', '18', '19']\n",
      "node 21 parents ['24', '17', '18', '19', '20']\n",
      "node 22 parents ['24', '17', '18', '19', '20', '21']\n",
      "node 23 parents ['24', '17', '18', '19', '20', '21', '22']\n",
      "node 31 parents ['24', '32']\n",
      "node 42 parents ['25', '26', '56', '69', '70', '71', '72']\n",
      "node 43 parents ['25', '26', '42']\n",
      "node 51 parents ['25', '50']\n",
      "node 40 parents ['26', '56']\n",
      "node 41 parents ['26']\n",
      "node 76 parents ['26', '49', '69', '70', '71', '72', '42']\n",
      "node 55 parents ['27', '50', '52', '56']\n",
      "node 46 parents ['29']\n",
      "node 53 parents ['52', '40']\n",
      "node 58 parents ['49', '56', '59', '65', '42']\n",
      "node 63 parents ['49', '56', '59', '65', '42', '58']\n",
      "node 47 parents ['49']\n",
      "node 48 parents ['47']\n",
      "node 60 parents ['49', '56', '59', '65', '58', '63']\n",
      "node 61 parents ['49', '59', '65', '63', '60']\n",
      "node 62 parents ['49', '56', '59', '65', '58', '63', '60', '61']\n",
      "node 64 parents ['49', '56', '59', '65', '58', '63', '60', '61', '62']\n",
      "node 66 parents ['49', '56', '59', '65', '58', '63', '60', '61', '62', '64']\n",
      "node 67 parents ['49', '59', '65', '63', '60', '61', '62', '64', '66']\n",
      "node 74 parents ['49']\n",
      "node 75 parents ['49', '74']\n",
      "node 77 parents ['49', '59', '65', '63', '64', '66', '67']\n",
      "node 57 parents ['50', '56']\n",
      "node 54 parents ['52']\n",
      "node 68 parents ['58']\n",
      "{1: [2], 2: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11], 3: [2, 4, 11], 4: [2, 3, 11], 5: [2], 6: [2], 7: [2], 8: [2], 9: [2], 10: [2], 11: [2, 3, 4, 12, 13, 14, 15, 16, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 49, 50, 52, 56, 59, 65, 69, 70, 71, 72, 73], 12: [11], 13: [11, 24], 14: [11], 15: [11], 16: [11], 24: [11, 13, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 30, 31, 32], 25: [11, 24, 26, 27, 28, 42, 43, 51, 69, 70, 71], 26: [11, 24, 25, 27, 28, 40, 41, 42, 43, 49, 56, 69, 70, 71, 72, 76], 27: [11, 18, 25, 26, 28, 44, 50, 52, 55, 56, 73], 28: [11, 24, 25, 26, 27, 29, 30, 32, 34, 44, 49, 59, 69, 70, 71, 72, 73], 29: [11, 28, 45, 46], 30: [11, 24, 28, 35, 36, 37, 38, 39], 32: [11, 24, 28, 31], 33: [11], 34: [11, 28], 35: [11, 30, 36, 37, 38, 39], 36: [11, 30, 35, 37, 38, 39], 37: [11, 30, 35, 36, 38, 39], 38: [11, 30, 35, 36, 37, 39], 39: [11, 30, 35, 36, 37, 38], 44: [11, 27, 28], 45: [11, 29], 49: [11, 26, 28, 47, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 75, 76, 77], 50: [11, 27, 51, 52, 55, 56, 57], 52: [11, 27, 50, 53, 54, 55, 56], 56: [11, 18, 26, 27, 40, 42, 49, 50, 52, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66], 59: [11, 28, 49, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 71, 77], 65: [11, 49, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 77], 69: [11, 25, 26, 28, 42, 49, 70, 71, 72, 76], 70: [11, 25, 26, 28, 42, 49, 69, 71, 72, 76], 71: [11, 25, 26, 28, 42, 59, 69, 70, 72, 76], 72: [11, 26, 28, 42, 49, 69, 70, 71, 76], 73: [11, 27, 28], 17: [18, 19, 20, 21, 22, 23, 24], 18: [17, 19, 20, 21, 22, 23, 24, 27, 56], 19: [17, 18, 20, 21, 22, 23, 24], 20: [17, 18, 19, 21, 22, 23, 24], 21: [17, 18, 19, 20, 22, 23, 24], 22: [17, 18, 19, 20, 21, 23, 24], 23: [17, 18, 19, 20, 21, 22, 24], 31: [24, 32], 42: [25, 26, 43, 56, 58, 63, 69, 70, 71, 72, 76], 43: [25, 26, 42], 51: [25, 50], 40: [26, 53, 56], 41: [26], 76: [26, 42, 49, 69, 70, 71, 72], 55: [27, 50, 52, 56], 46: [29], 53: [40, 52], 58: [42, 49, 56, 59, 60, 62, 63, 64, 65, 66, 68], 63: [42, 49, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 77], 47: [48, 49], 48: [47], 60: [49, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67], 61: [49, 59, 60, 62, 63, 64, 65, 66, 67], 62: [49, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67], 64: [49, 56, 58, 59, 60, 61, 62, 63, 65, 66, 67, 77], 66: [49, 56, 58, 59, 60, 61, 62, 63, 64, 65, 67, 77], 67: [49, 59, 60, 61, 62, 63, 64, 65, 66, 77], 74: [49, 75], 75: [49, 74], 77: [49, 59, 63, 64, 65, 66, 67], 57: [50, 56], 54: [52], 68: [58]}\n"
     ]
    }
   ],
   "source": [
    "def adjacent(file,dir = True):\n",
    "    nodes,edges = get_data(file)[2],get_data(file)[3]\n",
    "    adj = {int(node):[int(child) for child in child_nodes(edges,node)[1]] for node in nodes}\n",
    "\n",
    "    if dir == False:\n",
    "        for node in nodes:\n",
    "            parents = parent_nodes(edges,node)[1]\n",
    "            print('node',node,'parents',parents)\n",
    "            for parent in parents:\n",
    "                adj[int(node)].append(int(parent))\n",
    "    for node in adj:\n",
    "        adj[node] = sorted(adj[node])\n",
    "    return adj\n",
    "\n",
    "print(adjacent('Datasets/LesMiserables.dot',dir = False))\n",
    "\n",
    "\n",
    "def bfs_distance(graph, start):\n",
    "    visited = set()\n",
    "    distances = {start: 0}\n",
    "    queue = [start]\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.pop(0)\n",
    "        visited.add(current_node)\n",
    "\n",
    "        for neighbor in graph[current_node]:\n",
    "            if neighbor not in visited:\n",
    "                distances[neighbor] = distances[current_node] + 1\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def compute_distance_matrix(file,dir = True,p=False):\n",
    "    graph = adjacent(file,dir)\n",
    "    nodes = get_data(file)[2]\n",
    "\n",
    "    distance_matrix = {int(node):bfs_distance(graph, node) for node in graph}\n",
    "\n",
    "    for node1 in distance_matrix:\n",
    "        left_nodes = set([int(node) for node in nodes])-set(distance_matrix[node1].keys())\n",
    "        for node2 in left_nodes:\n",
    "            distance_matrix[node1][int(node2)] = -1\n",
    "            \n",
    "    ordered_dict = dict(OrderedDict(sorted({sub_dict: dict(OrderedDict(sorted(distance_matrix[sub_dict].items()))) for sub_dict in distance_matrix.keys() }.items())))\n",
    "    ans = [list(v.values()) for v in ordered_dict.values()]\n",
    "    if p== True:\n",
    "        print(\"Similarity matrix:\")\n",
    "        new_nodes = sorted([int(node) for node in nodes])\n",
    "        print(\"\\t\" + \"\\t\".join([str(node) for node in new_nodes]))\n",
    "        for i in range(len(node_list)):\n",
    "            print(new_nodes[i], \"\\t\", end=\"\")\n",
    "            for j in range(len(node_list)):\n",
    "                print(ans[i][j], \"\\t\", end=\"\")\n",
    "            print()\n",
    "    \n",
    "    return np.array(ans)\n",
    "\n",
    "\n",
    "#distance_matrix = compute_distance_matrix('Datasets/smallnet.dot',dir=False,p=True)\n",
    "\n",
    "#distance_matrix = compute_distance_matrix('Datasets/LesMiserables.dot',dir = False,p=True)\n",
    "#distance_matrix = compute_distance_matrix('Datasets/JazzNetwork.dot',dir = False)\n",
    "#distance_matrix = compute_distance_matrix('Datasets/LeagueNetwork.dot',p=True)\n",
    "#print(distance_matrix)\n",
    "# for node in distance_matrix:\n",
    "#     print(f\"Distances from node {node}: {distance_matrix[node]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  5 10 ...  6 21 31]\n",
      " [12  0 10 ... 14 12 15]\n",
      " [10 15  0 ... 15 12 24]\n",
      " ...\n",
      " [20 18 22 ...  0  9 16]\n",
      " [ 9  6  9 ...  8  0 12]\n",
      " [15 11 15 ... 14  5  0]]\n"
     ]
    }
   ],
   "source": [
    "new = np.array(distance_matrix)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(new))\n",
    "print(type(distance_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(distance_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'node_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Original dictionary\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#distance_matrix = distance_matrix \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#new_dict = {sub_dict: dict(OrderedDict(sorted(distance_matrix[sub_dict].items()))) for sub_dict in distance_matrix.keys() }\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#for sub_dict in distance_matrix.keys():\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#new_dict[sub_dict] =\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m new_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[38;5;28mint\u001b[39m(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnode_list\u001b[49m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m new_nodes]))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(node_list)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'node_list' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Original dictionary\n",
    "#distance_matrix = distance_matrix \n",
    "#new_dict = {sub_dict: dict(OrderedDict(sorted(distance_matrix[sub_dict].items()))) for sub_dict in distance_matrix.keys() }\n",
    "#for sub_dict in distance_matrix.keys():\n",
    "    #new_dict[sub_dict] =\n",
    "\n",
    "print(\"Similarity matrix:\")\n",
    "new_nodes = sorted([int(node) for node in node_list])\n",
    "print(\"\\t\" + \"\\t\".join([str(node) for node in new_nodes]))\n",
    "for i in range(len(node_list)):\n",
    "   print(new_nodes[i], \"\\t\", end=\"\")\n",
    "   for j in range(len(node_list)):\n",
    "       print(distance_matrix[i][j], \"\\t\", end=\"\")\n",
    "   print()\n",
    "\n",
    "#ordered_dict = dict(OrderedDict(sorted({sub_dict: dict(OrderedDict(sorted(distance_matrix[sub_dict].items()))) for sub_dict in distance_matrix.keys() }.items())))\n",
    "\n",
    "#print(new_dict)\n",
    "#print(distance_matrix)\n",
    "#print(ordered_dict) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(distances, node_list, edge_list, perplexity=10, learning_rate=300, n_iter=750, interactive=False):\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter, init='pca')\n",
    "    embeddings = tsne.fit_transform(distances)\n",
    "\n",
    "    kl_div = tsne.kl_divergence_\n",
    "    for i in range(n_iter):\n",
    "        print(f\"Iteration {i+1}: KL divergence = {kl_div}\")\n",
    "        if kl_div < 0.05:\n",
    "            print(f\"t-SNE has converged in iteration n. {i+1}\")\n",
    "            break\n",
    "\n",
    "    # KMeans clustering\n",
    "    # kmeans = KMeans(n_clusters=8)  # You can adjust the number of clusters\n",
    "    # labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    #plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='viridis', s=50)\n",
    "    plt.scatter(embeddings[:, 0], embeddings[:, 1], cmap='viridis', s=50)\n",
    "\n",
    "    for edge in edge_list:\n",
    "        u, v = edge\n",
    "        u_index = node_list.index(u)\n",
    "        v_index = node_list.index(v)\n",
    "        plt.plot([embeddings[u_index, 0], embeddings[v_index, 0]], \n",
    "                    [embeddings[u_index, 1], embeddings[v_index, 1]], \n",
    "                    color='gray', alpha=0.2)\n",
    "\n",
    "    for i, node_number in enumerate(node_list):\n",
    "        plt.text(embeddings[i, 0], embeddings[i, 1], node_number, color='black')\n",
    "\n",
    "    plt.title('t-SNE Visualization of Node Similarities')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.grid(True)\n",
    "    #plt.colorbar(label='Cluster ID')\n",
    "    plt.colorbar(label='Similarity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miserables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes,edges,node_list,edge_list,weights = get_data_step6('Datasets/LesMiserables.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.5        0.         ... 0.         0.         0.        ]\n",
      " [0.5        1.         0.11111111 ... 0.         0.         0.        ]\n",
      " [0.         0.11111111 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         1.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]]\n",
      "Similarity matrix:\n",
      "\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t24\t25\t26\t27\t28\t29\t30\t32\t33\t34\t35\t36\t37\t38\t39\t44\t45\t49\t50\t52\t56\t59\t65\t69\t70\t71\t72\t73\t17\t18\t19\t20\t21\t22\t23\t31\t42\t43\t51\t40\t41\t76\t55\t46\t53\t58\t63\t47\t48\t60\t61\t62\t64\t66\t67\t74\t75\t77\t57\t54\t68\n",
      "1 \t1.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "2 \t0.50 \t1.00 \t0.11 \t0.09 \t0.50 \t0.50 \t0.50 \t0.50 \t0.33 \t0.50 \t0.17 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "3 \t0.00 \t0.11 \t1.00 \t0.14 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "4 \t0.00 \t0.09 \t0.14 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "5 \t0.00 \t0.50 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "6 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "7 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "8 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "9 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "10 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "11 \t0.00 \t0.17 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.50 \t0.50 \t0.50 \t0.50 \t0.50 \t0.10 \t0.12 \t0.08 \t0.03 \t0.06 \t0.11 \t0.33 \t0.25 \t0.50 \t0.33 \t0.25 \t0.25 \t0.33 \t0.33 \t0.33 \t0.25 \t0.50 \t0.50 \t0.33 \t0.33 \t0.05 \t0.20 \t0.50 \t0.50 \t0.50 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "12 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "13 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "14 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "15 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "16 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "24 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.10 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t1.00 \t0.33 \t0.50 \t0.00 \t0.17 \t0.00 \t0.50 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.25 \t0.25 \t0.20 \t0.20 \t0.20 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.12 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t1.00 \t0.07 \t0.20 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "26 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.08 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.07 \t1.00 \t0.50 \t0.17 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.17 \t0.14 \t0.20 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.33 \t0.00 \t0.50 \t0.50 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "27 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.03 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.50 \t1.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.25 \t0.33 \t0.05 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "28 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.06 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.17 \t0.50 \t0.17 \t0.50 \t1.00 \t0.50 \t0.50 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.14 \t0.00 \t0.50 \t0.33 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "29 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.11 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "30 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.33 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "32 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "34 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "35 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t1.00 \t0.25 \t0.33 \t0.33 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "36 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.25 \t1.00 \t0.33 \t0.33 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "37 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.33 \t0.33 \t1.00 \t0.33 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "38 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.33 \t0.33 \t0.33 \t1.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "39 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.33 \t0.33 \t0.33 \t0.33 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "44 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "45 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "49 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.20 \t0.12 \t0.17 \t0.50 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.50 \t0.12 \t0.33 \t0.00 \t0.14 \t0.50 \t0.33 \t0.17 \t0.25 \t0.50 \t0.33 \t0.33 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.10 \t0.08 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t\n",
      "52 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.10 \t1.00 \t0.14 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t\n",
      "56 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.05 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.05 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.08 \t0.14 \t1.00 \t0.12 \t0.17 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.17 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.50 \t0.10 \t0.00 \t0.00 \t0.17 \t0.00 \t0.50 \t0.50 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t\n",
      "59 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.14 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.12 \t0.00 \t0.00 \t0.12 \t1.00 \t0.09 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.06 \t0.00 \t0.00 \t0.06 \t0.20 \t0.14 \t0.20 \t0.17 \t0.25 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "65 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.17 \t0.00 \t0.00 \t0.17 \t0.09 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.08 \t0.00 \t0.00 \t0.10 \t0.33 \t0.14 \t0.20 \t0.12 \t0.25 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "69 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.17 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.14 \t0.20 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "70 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.14 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.14 \t1.00 \t0.20 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "71 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.20 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.20 \t0.20 \t1.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "72 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.33 \t0.33 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "73 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "17 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.20 \t0.20 \t0.20 \t0.25 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "18 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t1.00 \t0.20 \t0.20 \t0.25 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "19 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.20 \t1.00 \t0.20 \t0.25 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.20 \t0.20 \t1.00 \t0.20 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "21 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.25 \t0.20 \t1.00 \t0.17 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "22 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.25 \t0.25 \t0.17 \t1.00 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "23 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.25 \t0.25 \t0.20 \t0.20 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "31 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "42 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.17 \t0.00 \t0.00 \t0.50 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "43 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "51 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "40 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "41 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "76 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "55 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.33 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "46 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "53 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "58 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.33 \t0.00 \t0.00 \t0.33 \t0.00 \t0.50 \t0.33 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t\n",
      "63 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.12 \t0.00 \t0.00 \t0.10 \t0.06 \t0.08 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t1.00 \t0.00 \t0.00 \t0.07 \t0.25 \t0.14 \t0.14 \t0.17 \t0.33 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "47 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "48 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "60 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.14 \t0.00 \t0.00 \t0.17 \t0.06 \t0.10 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.07 \t0.00 \t0.00 \t1.00 \t0.33 \t0.17 \t0.17 \t0.17 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "61 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.20 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.33 \t1.00 \t0.33 \t0.33 \t0.33 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "62 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.50 \t0.14 \t0.14 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.14 \t0.00 \t0.00 \t0.17 \t0.33 \t1.00 \t0.25 \t0.17 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "64 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.17 \t0.00 \t0.00 \t0.50 \t0.20 \t0.20 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.14 \t0.00 \t0.00 \t0.17 \t0.33 \t0.25 \t1.00 \t0.17 \t0.50 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "66 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.33 \t0.17 \t0.12 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.17 \t0.00 \t0.00 \t0.17 \t0.33 \t0.17 \t0.17 \t1.00 \t0.33 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "67 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.25 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.50 \t0.50 \t0.50 \t0.50 \t0.33 \t1.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t\n",
      "74 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "75 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.33 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t1.00 \t0.00 \t0.00 \t0.00 \t0.00 \t\n",
      "77 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.50 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.50 \t0.50 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t0.00 \t\n",
      "57 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t0.00 \t\n",
      "54 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.50 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t0.00 \t\n",
      "68 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.25 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t0.00 \t1.00 \t\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity_matrix(node_list, edge_list, weights):\n",
    "    edge_weights = {(u, v): weight for (u, v), weight in weights.items()}\n",
    "\n",
    "    num_nodes = len(node_list)\n",
    "    distances = np.zeros((num_nodes, num_nodes))\n",
    "    for i, source in enumerate(node_list):\n",
    "        for j, target in enumerate(node_list):\n",
    "            if i != j:\n",
    "                if (source, target) in edge_weights:\n",
    "                    distances[i, j] = edge_weights[(source, target)]\n",
    "                elif (target, source) in edge_weights:\n",
    "                    distances[i, j] = edge_weights[(target, source)]\n",
    "                else:\n",
    "                    distances[i, j] = np.inf\n",
    "\n",
    "    similarities = np.zeros((num_nodes, num_nodes))\n",
    "    for u, v in edge_list:\n",
    "        i = node_list.index(u)\n",
    "        j = node_list.index(v)\n",
    "        similarities[i, j] = 1 / (1 + distances[i, j])\n",
    "        similarities[j, i] = similarities[i, j]  # Similarity matrix is symmetric\n",
    "\n",
    "    np.fill_diagonal(similarities, 1) #diagonal 1\n",
    "\n",
    "    return similarities\n",
    "\n",
    "similarity_matrix = compute_similarity_matrix(node_list, edge_list, weights)\n",
    "print(similarity_matrix)\n",
    "print(\"Similarity matrix:\")\n",
    "print(\"\\t\" + \"\\t\".join(node_list))\n",
    "for i in range(len(node_list)):\n",
    "   print(node_list[i], \"\\t\", end=\"\")\n",
    "   for j in range(len(node_list)):\n",
    "       print(\"{:.2f}\".format(similarity_matrix[i, j]), \"\\t\", end=\"\")\n",
    "   print()\n",
    "\n",
    "similarities = compute_similarity_matrix(node_list, edge_list, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floyd_warshall(node_list, edge_list, weights):\n",
    "    num_nodes = len(node_list)\n",
    "    \n",
    "    distances = np.full((num_nodes, num_nodes), np.inf)\n",
    "\n",
    "    np.fill_diagonal(distances, 0)\n",
    "\n",
    "    for (u, v), weight in weights.items():\n",
    "        i = node_list.index(u)\n",
    "        j = node_list.index(v)\n",
    "        distances[i, j] = weight\n",
    "        distances[j, i] = weight  # If the graph is undirected\n",
    "\n",
    "    for k in range(num_nodes):\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                distances[i, j] = min(distances[i, j], distances[i, k] + distances[k, j])\n",
    "\n",
    "    return distances\n",
    "\n",
    "distances = floyd_warshall(node_list, edge_list, weights)\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(distances, node_list, edge_list, perplexity=15, learning_rate=300, n_iter=1000, interactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jazz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes,edges,node_list,edge_list,weights = get_data_step6('Datasets/JazzNetwork.dot')\n",
    "\n",
    "#print(nodes) \n",
    "#print(edges)\n",
    "#print(node_list)\n",
    "#print(edge_list)\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(node_list, edge_list): #no wweights\n",
    "    num_nodes = len(node_list)\n",
    "    \n",
    "    distances = np.full((num_nodes, num_nodes), np.inf)\n",
    "    \n",
    "    for u, v in edge_list:\n",
    "        i = node_list.index(u)\n",
    "        j = node_list.index(v)\n",
    "        distances[i, j] = 1\n",
    "        distances[j, i] = 1\n",
    "    \n",
    "    similarities = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                similarities[i, j] = 1 / (1 + distances[i, j])\n",
    "    \n",
    "    np.fill_diagonal(similarities, 1)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "similarities = compute_similarity_matrix(node_list, edge_list)\n",
    "\n",
    "#print(\"Similarity matrix:\")\n",
    "#print(\"\\t\" + \"\\t\".join(node_list))\n",
    "#for i in range(len(node_list)):\n",
    "#    print(node_list[i], \"\\t\", end=\"\")\n",
    "#    for j in range(len(node_list)):\n",
    "#        print(\"{:.2f}\".format(similarities[i, j]), \"\\t\", end=\"\")\n",
    "#    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(similarities, node_list, edge_list, perplexity=15, learning_rate=250, n_iter=1500, interactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes,edges,node_list,edge_list,weights = get_data_league('Datasets/LeagueNetwork.dot')\n",
    "\n",
    "#print(nodes) \n",
    "#print(edges)\n",
    "#print(node_list)\n",
    "#print(edge_list)\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix_league(node_list, edge_list, weights):\n",
    "    edge_weights = {(u, v): weight for (u, v), weight in weights.items()}\n",
    "\n",
    "    num_nodes = len(node_list)\n",
    "    distances = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i, source in enumerate(node_list):\n",
    "        for j, target in enumerate(node_list):\n",
    "            if i != j:\n",
    "                if (source, target) in edge_weights:\n",
    "                    distances[i, j] = edge_weights[(source, target)]\n",
    "                else:\n",
    "                    distances[i, j] = -edge_weights[(target, source)] if (target, source) in edge_weights else np.inf\n",
    "\n",
    "    similarities = np.zeros((num_nodes, num_nodes))\n",
    "    for u, v in edge_list:\n",
    "        i = node_list.index(u)\n",
    "        j = node_list.index(v)\n",
    "        similarities[i, j] = 1 / (1 + abs(distances[i, j])) if distances[i, j] != np.inf else 0 \n",
    "        similarities[j, i] = similarities[i, j]  \n",
    "\n",
    "    np.fill_diagonal(similarities, 1)  # Diagonal set to 1\n",
    "\n",
    "    return similarities\n",
    "\n",
    "similarities = compute_similarity_matrix_league(node_list, edge_list, weights)\n",
    "\n",
    "#print(\"Similarity matrix:\")\n",
    "#print(\"\\t\" + \"\\t\".join(node_list))\n",
    "#for i in range(len(node_list)):\n",
    "#    print(node_list[i], \"\\t\", end=\"\")\n",
    "#    for j in range(len(node_list)):\n",
    "#        print(\"{:.2f}\".format(similarities[i, j]), \"\\t\", end=\"\")\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(similarities, node_list, edge_list, perplexity=10, learning_rate=200, n_iter=1000, interactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_continuity(similarities, distances_Y, k=5):\n",
    "    \"\"\"\n",
    "    Compute continuity metric for t-SNE projection.\n",
    "\n",
    "    Parameters:\n",
    "    - similarities: Similarity matrix for the high-dimensional data.\n",
    "    - distances_Y: Euclidean distances for the t-SNE projected points in 2D space.\n",
    "    - k: Number of neighbors to consider.\n",
    "\n",
    "    Returns:\n",
    "    - Continuity score.\n",
    "    \"\"\"\n",
    "    n = len(similarities)\n",
    "\n",
    "    nn_orig = similarities.argsort()\n",
    "    nn_proj = distances_Y.argsort()\n",
    "\n",
    "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
    "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
    "\n",
    "    sum_i = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        V = np.setdiff1d(knn_orig[i], knn_proj[i])\n",
    "\n",
    "        sum_j = 0\n",
    "        for j in range(V.shape[0]):\n",
    "            sum_j += np.where(nn_proj[i] == V[j])[0] - k\n",
    "\n",
    "        sum_i += sum_j\n",
    "\n",
    "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)).squeeze())\n",
    "\n",
    "def compute_trustworthiness(similarities, distances_Y, k=5):\n",
    "    \"\"\"\n",
    "    Compute trustworthiness metric for t-SNE projection.\n",
    "\n",
    "    Parameters:\n",
    "    - similarities: Similarity matrix for the high-dimensional data.\n",
    "    - distances_Y: Euclidean distances for the t-SNE projected points in 2D space.\n",
    "    - k: Number of neighbors to consider.\n",
    "\n",
    "    Returns:\n",
    "    - Trustworthiness score.\n",
    "    \"\"\"\n",
    "    n = len(similarities)\n",
    "\n",
    "    nn_orig = similarities.argsort()\n",
    "    nn_proj = distances_Y.argsort()\n",
    "\n",
    "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
    "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
    "\n",
    "    sum_i = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        U = np.setdiff1d(knn_proj[i], knn_orig[i])\n",
    "\n",
    "        sum_j = 0\n",
    "        for j in range(U.shape[0]):\n",
    "            sum_j += np.where(nn_orig[i] == U[j])[0] - k\n",
    "\n",
    "        sum_i += sum_j\n",
    "\n",
    "    trustworthiness_score = float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)).squeeze())\n",
    "    return trustworthiness_score\n",
    "\n",
    "def compute_stress(similarities, distances_Y):\n",
    "    \n",
    "    #print(f\"similarities: {similarities}\")\n",
    "    #print(f\"distances_Y: {distances_Y}\")\n",
    "    #n = len(similarities)\n",
    "    \n",
    "    # Create a mask to ignore the diagonal and only consider the lower triangular part\n",
    "    #mask = np.tri(n, k=-1)\n",
    "    stress = np.sum((similarities - distances_Y)**2) / np.sum(similarities**2)\n",
    "    #stress = np.sum((similarities - distances_Y)**2 * mask) / np.sum(similarities**2 * mask)\n",
    "\n",
    "    return stress\n",
    "\n",
    "def compute_shepard(distances_highD, distances_lowD):\n",
    "    \n",
    "    shepard_values = []\n",
    "    plt.scatter(distances_highD, distances_lowD)\n",
    "\n",
    "    return shepard_values\n",
    "\n",
    "#def metric_pq_shepard_diagram_correlation(id_run, dataset_name):\n",
    "#    global DISTANCES\n",
    "#\n",
    "#    D_high = np.load(DISTANCES['D_high_list'], mmap_mode='c')\n",
    "#    D_low = np.load(DISTANCES[id_run]['D_low_list'], mmap_mode='c')\n",
    "#\n",
    "#    return stats.spearmanr(D_high, D_low)[0]\n",
    "\n",
    "def floyd_warshall(node_list, edge_list, weights):\n",
    "    num_nodes = len(node_list)\n",
    "    \n",
    "    distances = np.full((num_nodes, num_nodes), np.inf)\n",
    "\n",
    "    np.fill_diagonal(distances, 0)\n",
    "\n",
    "    for (u, v), weight in weights.items():\n",
    "        i = node_list.index(u)\n",
    "        j = node_list.index(v)\n",
    "        distances[i, j] = weight\n",
    "        distances[j, i] = weight  # If the graph is undirected\n",
    "\n",
    "    for k in range(num_nodes):\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                distances[i, j] = min(distances[i, j], distances[i, k] + distances[k, j])\n",
    "\n",
    "    return distances\n",
    "\n",
    "distances = floyd_warshall(node_list, edge_list, weights)\n",
    "print(distances)\n",
    "\n",
    "def plot_tsne_testing(distances, node_list, edge_list, perplexity=10, learning_rate=300, n_iter=750):\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter, init='pca')\n",
    "    embeddings = tsne.fit_transform(distances)\n",
    "    distances_Y = euclidean_distances(embeddings)\n",
    "    #kl_div = tsne.kl_divergence_\n",
    "    #for i in range(n_iter):\n",
    "    #    print(f\"Iteration {i+1}: KL divergence = {kl_div}\")\n",
    "    #    if kl_div < 0.05:\n",
    "    #        print(f\"t-SNE has converged in iteration n. {i+1}\")\n",
    "    #        break\n",
    "\n",
    "    continuity_score = compute_continuity(similarities, distances_Y)\n",
    "    trustworthiness_score = compute_trustworthiness(similarities, distances_Y)\n",
    "    stress = compute_stress(similarities, distances_Y)\n",
    "    shepard_values = compute_shepard(similarities.flatten(), distances_Y.flatten())\n",
    "\n",
    "    print(f\"Continuity {continuity_score}\")\n",
    "    print(f\"Trustworthiness {trustworthiness_score}\")\n",
    "    print(f\"Stress {stress}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(embeddings[:, 0], embeddings[:, 1], cmap='viridis', s=50)\n",
    "\n",
    "    for edge in edge_list:\n",
    "        u, v = edge\n",
    "        u_index = node_list.index(u)\n",
    "        v_index = node_list.index(v)\n",
    "        plt.plot([embeddings[u_index, 0], embeddings[v_index, 0]], \n",
    "                 [embeddings[u_index, 1], embeddings[v_index, 1]], \n",
    "                 color='gray', alpha=0.2)\n",
    "\n",
    "    for i, node_number in enumerate(node_list):\n",
    "        plt.text(embeddings[i, 0], embeddings[i, 1], node_number, color='black')\n",
    "\n",
    "    plt.title('t-SNE Visualization of Node Similarities')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    #plt.grid(True)\n",
    "    #plt.colorbar(label='Similarity')\n",
    "    plt.show()\n",
    "\n",
    "nodes, edges, node_list, edge_list, weights = get_data_step6('Datasets/LesMiserables.dot')\n",
    "similarities = compute_similarity_matrix(node_list, edge_list, weights)\n",
    "plot_tsne_testing(similarities, node_list, edge_list, perplexity=10,learning_rate=300, n_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
